# Real-Time Toxicity Detection in Online Communication Platforms

This project focuses on detecting toxic or abusive messages in online chats using 
Natural Language Processing (NLP) and Machine Learning techniques.

Initially, the system was designed to filter toxic messages in online gaming chats, 
where abusive language is a common issue. However, the scope was later expanded to 
support general communication platforms such as social media, forums, and online 
discussion systems.

The goal is to build a system that can classify messages as toxic or non-toxic to 
support safer online communication across different digital environments.

## Objectives
- Identify harmful or abusive chat messages  
- Classify messages based on toxicity level  
- Use NLP techniques for text processing  
- Build a simple user interface for testing  

## Technologies Used
- Python  
- Pandas, NumPy  
- Scikit-learn  
- TF-IDF Vectorizer  
- Logistic Regression  
- Streamlit  

## Team Members
- Somyansh Bishnoi  
- Preksha Verma  
